#Arguments needed by main.py
scenario: PredatorCapturePrey #name of the folder inside scenarios

#### Robotarium试验场地的边界
LEFT: -1.4
RIGHT: 1.4
UP: -0.9
DOWN: .9
# 每个robot每一个时间步移动的距离
step_dist : 0.2
# 是否使用随机种子[-1不随机][任意其他数字 随机]
seed: -1
# robot的初始位置相距彼此的最小距离
start_dist: 0.3
# 是否生成图片 [-1 不要图片] [当发送到Robotarium时是1]
show_figure_frequency: -1
#### Robotarium自带的参数
# 训练时是false, 提交的时候是true
robotarium: False
# 是否使用真实的robotarium
real_time: False
# 防止robot碰撞的参数
barrier_certificate: safe #Can be safe or default for strong or weak barrier certificates
update_frequency: 29

n_actions: 5 # 每个agent的动作空间
n_agents: 4  # 每个coalition中的agent数量
predator: 2
capture: 2
num_prey: 6
num_neighbors: 3

### reward相关的参数
time_penalty: -0.05
sense_reward: 1
capture_reward: 5
penalize_violations: True #If true, agents get a negative reward for collisions or boundary infractions and the episode stops
### done相关的参数
# 最大的episode步数
max_episode_steps: 80

### obs相关的参数
predator_radius: .45
capture_radius: .25

capability_aware: False #If true, the agents know their capture/sensing radius. Probably shouldn't use ids if true. Make sure this argument matches how the models were trained


### reset相关的参数
#Minimum distance the agents start from each other
ROBOT_INIT_RIGHT_THRESH : -0.5
PREY_INIT_LEFT_THRESH : 0.5






#model_config_file: qmix.json
#model_file: qmix.th
#
#actor_file: rnn_agent
#actor_class: RNNAgent
#
#env_file: PredatorCapturePrey
#env_class: PredatorCapturePrey #This needs to have all of the functionalities of a gym to work
#
#episodes: 10 #Number of episodes to run for
#shared_reward: True
# #sets the seed. Set to -1 to use a random seed.
